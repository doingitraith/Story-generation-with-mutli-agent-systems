\chapter{Theory} %25 pages
This chapter presents the various fields of study that were encountered or utilized while developing the game mechanic and its implementing prototype game. This includes narratology, game and quest theory, information theory, multi-agent systems, consensus protocols, emotion engines, and inference engines.
\section{What is a story?}
There exist a multitude of definitions of what a story is. Rayfield argues that a story is a narrative item that exists throughout all cultures. He concludes that there exists a universal concept of a certain structure that listeners will recognize as a story. He limits this structure by the degree of complexity and argues that listeners will only recognize the structure as a story within certain minimal and maximal bounds of complexity. These bounds would then be the same across all cultures.~\cite{Rayfield1972} Scheub takes another approach and sees story more as "a means whereby people come to terms with their lives, their past; it is a way of understanding their relationship within the context of their traditions. It is a means of accessing and valuing history: in the end story \textit{is} history."~\cite{Scheub1998} Lastly, the Oxford Dictionary of Literary Terms more formally describes a story as a set of events that are selected and arranged in a specific order and told by a narrator. The specific order of the events is called the plot.~\cite{Baldick1996}\\
One thing that most definitions have in common, however, is that stories are an important tool for humans. Stories help us to interpret and process information and experiences. They enrich subjectively perceived facts and form them into each person's individual truth. This is the \textit{"meaning"} of a story. This "meaning-making" is also part of the psychological process in self-identification and the creation of memories~\cite{Flanagan1992}. Stories are furthermore an important factor in human communication, used as parables and examples to illustrate points. Storytelling was one of the earliest forms of entertainment.\\
When looking into definitions of what a story \textit{is}, the matter quite quickly goes into the area of what a story \textit{does}. I already mentioned how it is a vital tool for the human psyche, but there are some more concrete functions that stories fulfill.
\subsection{Functions of Storytelling}
The motifs and contents of stories and the modes of narration are highly culturally individual aspects. The functions these elements serve, though, can be found across all cultures. One example is to make one narration more understandable by putting it into relation with another story. This is commonly referred to as a metaphor. Now, these relational stories don't have to be imaginary per se. They can be a retelling of events that have actually transpired and help underline the point of the narrator. On the far hand of abstracting stories to make a point is the very careful use of words to find an objective true transpiring of events. This is what happens in courtrooms. It is a retelling of events, but the order and selection are so careful, so meticulous, that an actual fair "true" story might be revealed.~\cite{Rigney1992}\\
As mentioned above, stories and storytelling are used to share and interpret experiences. The human brain is evolutionarily predisposed to process, store and recall memories in the form of stories~\cite{Wyer2014}. Humans think in narrative structures and mostly remember facts in the form of a story. Facts are smaller versions linked to a larger story, which supports analytical thinking.~\cite{Connelly1990} This makes storytelling such a great tool for teaching as well. There is research about how storytelling is a meaningful teaching method that can be applied in education to encourage the development of caring, empathy, compassion, and a deeper cultural understanding.~\cite{Davidson2004} It is not event solely the listening person who is learning from a story. Often the discovery of a personal meaning of a story is only made visible when telling a story. Thus also the storyteller can learn something new.~\cite{Doty2003}\\
This is applied in therapeutic storytelling, where through retelling experiences in story form, the storyteller attempts to better understand their own thoughts and situation. This can be supported by questions from a therapist who carefully steers the storyteller through their narration to pinpoint insights.~\cite{Lawless2001}\\
There are countless situations where we encounter storytelling precisely because we want to share experiences and emotions. Stories are used to inspire and motivate, manage conflicts, for marketing, or for political practice~\cite{Jameson2001}. These are all situations where the intent is separate from the story itself. Where we turn to storytelling because the human brain can process them so effectively. Another aspect is, however, when we tell stories for the story's sake.
\subsection{The Appeal of Stories}
I have now established that there is a difference between the intention of storytelling itself and utilizing it for another purpose. The difference is that we do not enter a courtroom to tell or listen to a story. We do so to find the truth. The past has simply shown us that the careful recounting of events combined with precise inquiry has proven a good way to do so. So when we do not tell stories as a means of achieving another intention, we also share them just because they are stories. For this, we can take on both positions, that of the narrator or the listener. Again, a multitude of situations presents itself for these applications. We listen to bedtime stories that our elders tell us. We tell a funny anecdote to our friends on a night out. Humans have created whole industries around the consumption of stories. We read books to immerse ourselves into stories, we watch movies or shows, and we play narrative video games. The fact that so much of our time is willfully spent listening to, watching, or interacting with stories, must mean that there is something worthwhile there. The mere consumption of narration seems to be satisfying in itself.\\
When we hear stories, the brain releases the hormone Oxytocin. This hormone heightens feelings of trust, empathy, and compassion. It positively influences social behavior and helps us to feel more connected to others.~\cite{Gottschall2012} Humans are inherently social beings. We want to connect to others around us. We try to create situations and use known cultural signals to connect on a non-verbal level. Humans mimic body language, laugh more in a social situation than alone or use physical contact to communicate.~\cite{Frith2007}\\
When we hear a story, the brain is enabled to form connections to the people who listen to the story with us, to the narrator, and to the characters in the story. Communication is a shared activity resulting in a transfer of information across brains. Research shows that during successful communication, the brains of both the speaker and the listener shows common, temporally linked response activities. When we hear a story, our brain mirrors activities in the sensory center of the storyteller.~\cite{Stephens2010} This attempt to sync brain activity is a deeply social connection. It also means that when we hear an enjoyable story, the brain behaves as if we would experience it ourselves.
\subsection{Stories in Media}
The consumption of stories has led to the creation of huge industries that focus entirely on creating and delivering stories to customers around the world through different kinds of media. That term comes from the Latin word \textit{medium} for "middle", which again stems from the ancient Greek word \textit{méson} for "the middle" or "the public". Today we use the term media as a word for "the means of communication".~\cite{Hoffmann2000} In the context of storytelling, this could be oral through a present storyteller, audio through an audiobook, visual through a book or e-book, audiovisual through theater plays, movies or series, or interactive through games and other interactive media. Oftentimes, when we talk about "the media" today, we refer to an industrialized consumption of content or news.\\
The economic factor of these storytelling media cannot be underestimated. The global Entertainment \& Media Outlook analysis from PriceWaterhouseCoopers reports over US\$~40bn for global box office revenue in cinemas for 2019. Cinema revenue, of course, took a nosedive because of the COVID-19 pandemic in 2020 and 2021 but is expected to recover and grow by 2023. Video games, however, have been steadily growing to roughly US\$~62bn for traditional games revenue and almost US\$~92bn for social or casual gaming revenue in 2021. These numbers are also expected to grow in the coming years.~\cite{PwC2021}\\
Storytelling, of course, works differently and has different requirements in each of these mediums. Books, for example, allow for a seamless switch of inward and outward perspectives of characters or thought processes. Movies as an audiovisual medium are more restricted to an outward perspective and have to use different storytelling techniques to transport the inner feelings of characters. There is also a structural difference to all these forms of media since there are conventions for runtime for movies or an episode of a  show.~\cite{Ryan2004}\\
The requirements for video game stories stem greatly from the fact that there is a distinction between the human player in front of the screen, which controls a player character, and this character who inhabits and acts in the game world. In the story that we experience in the game, the plot points that we traverse were aptly defined with the term of narrative by Abbot. Similarly to Baldick in the Oxford Dictionary of Literary Terms, he says that narrative is the representation of an event or an action or a series of events or actions. He further argues that without action, only description or exposition remains~\cite{Abbott2020}. This leads to the idea that narrative can only exist when there is a transition from one state into another. This transition of states is then an event or an action. It fits well with how Aristotle described a story as a whole that "[...] has a beginning and middle and end."~\cite{Aristotle2006}. This idea also implies the existence of at least three states in a story, the beginning, the middle, and the end, in addition to the transitions in between. These transitions would be, according to Abbot, the narrative.
\subsection{Expectation \& Feedback}
\label{section:expfee}
Players have certainly learned expectations when controlling a player character in a narrative game. They expect their gameplay actions to faithfully represent the motives of the character on the screen. When I talk about the player character, I refer to the virtual character in the game world as a function of the human player who controls them on-screen. It is the character we follow in the story. In their work about Character and Conflict, Lankoski and Heliö argue that a narrative state transition, an action, is the most important feature from the player’s point of view~\cite{Lankoski2002}. They also argue that character-driven action is very similar to character-driven writing, a similarity that is especially important for story-driven games. They say, "[...] instead of writing a story, characters and their needs are designed so that there will be enough action and conflict in the game to make it playable and interesting."~\cite{Lankoski2002} This makes motivation or needs so important for directing action and keeping a game interesting.\\
This idea of actions that make a game playable and interesting is well explained with the definition of agency by Wardrip-Fruin et al. They define agency as a phenomenon involving both player and game. It "occurs when the actions players desire are among those they can take (and vice versa) as supported by an underlying computational model."~\cite{Rohtua2009} They shift the focus of a definition of agency toward a question of how games can evoke desires that can be satisfied by the game systems. Or how said systems can be created. Towards how to manage player expectations and early on explain the game systems so that player expectations and thus player agency can adapt. This finally brings me to the term of the avatar. Klevjer agrees that avatars are "little more than a cursor" to facilitate player agency in the game. They are tools to fulfill the actions that the player wants to perform~\cite{Klevjer2012}. So the term avatar stands on the opposite side of the term player character. One is the tool used by the player to create meaningful actions, and the other is a character in a narrative with goals and motivations. If the game manages to merge the motivations of the player and the player character, then the game succeeds in creating agency.\\
This makes agency one of the primary requirements for a video game story. Callele et al. call the game designers’ intent or the target emotional state and the means by which the game designer expects the production team to induce that emotional state in the player \textit{the emotional requirement}. This requirement needs game developers and storytellers to carefully align their intentions. They need to take cultural, spatial, and relational aspects of gameplay events and symbols into account to ensure that their intended emotion is transferred to the player.~\cite{Callele2008}\\
Another requirement for game stories is one of more concrete communication. Games convey meaning different from other forms of media. Every game brings with it a specific set of semantics, the game rules that need to be properly communicated to the player in order for them to be able to play it. A player who understands the game’s rules knows the available actions they can take. This allows them to adjust their expectations to their character and the story. If the story presents the player character as a legendary warrior capable of defeating any enemy, but the game gives me no option to engage in combat, the player will possibly not understand how the reputation of the character came to be in the first place. Likewise, a pacifistic character with an arsenal at their disposal will create a similar conflict of intentions between the game and the player. Rule conventions also sometimes dictate feedback that the player expects. An example would be if the player triggers the input for a \textit{move right} action, they expect the character to move to the right on the screen. This creates an interplay between expectations and feedback that comprises both gameplay and narrative. Symbols come with certain expectations for actions to be available to the player, and events triggered by actions come with certain expectations of feedback to be received from the game.
\subsection{The optimal Experience}
A synchronization between expectation and feedback is also something Csikszentmihalyi describes when he talks about the \textit{optimal experience}. He describes incidents when a sense of exhilaration and of deep enjoyment is felt. These moments are often highly active and not receptive or relaxing times. They occur especially when we engage in a voluntary endeavor to do something difficult or worthwhile. Optimal experiences result when there is order in the consciousness. This happens when we are focused on a realistic set of goals with our skills matching the opportunities for action. It can be easily seen how this translates very well to gameplay in video games. Goals allow people to concentrate attention on the task at hand, with other things fading into the background. The key element of an optimal experience is that it is an end in itself. It may be taken on for other reasons initially, but the activity soon will become intrinsically rewarding. It has to be autotelic. The term is formed from the Greek words for \textit{self} and \textit{goal} respectively, and means the activity has an end or purpose in itself.~\cite{Csikszentmihalyi1990}\\
I have established earlier that experiencing stories is, in fact, an autotelic activity. With the science of optimal experience, we can assume that a game mechanic that could satisfy narrative requirements would indeed create a very rewarding gameplay experience.
\subsection{Quests}
Narrative-focused games often feature a very specific concept for compartmentalizing their stories - the \textit{quest}. The word has Latin origin in the word \textit{quaesta} for inquire or search. In literary it has long been known the describe the difficult, often symbolic, or allegoric journey towards a goal. It plays a central role in Joseph Campbell's \textit{"Hero's Journey"}, where he says, "\textit{[...]the hero sets forth from the world of common day into a land of adventures, tests, and magical rewards. Most times in a quest, the knight in shining armor wins the heart of a beautiful maiden/ princess}"~\cite{Campbell2008}. Video games also have been using the term for decades for a isolated concrete set of goals that marks a progression. A quest is a task, a mission. It has a set of goals that need to be completed in order for the quest to be finished.\\
Aarseth defines three basic quest types that can be combined and rearranged to create complex structures:
\begin{itemize}
	\item \textbf{Place-oriented}: The quest requires the player to move from a starting position $A$ to a target position $B$. Typically, the player will encounter obstacles along the way, but the basic premise remains.
	\item \textbf{Time-oriented}: These quests add a time-related aspect to the goal. For example: \textit{"Survive for $X$ seconds."} or \textit{"Find three apples in $Y$ seconds."}
	\item \textbf{Objective-oriented}: This includes a concrete result to the goal requirement. For example, \textit{"Get item $I$ from character $J$."} A specific condition needs to be met for the goal to be finished.
\end{itemize} 
The basic types can be combined, nested, serialized, or parallelized in order to create highly complex quest worlds. Common types are the serial arrangement of quests into a linear corridor, a semi-open hub, and an open landscape.~\cite{Aarseth2005}\\
Open quest-landscapes are often featured in open-world role-playing games like \textit{The Elder Scrolls V: Skyrim}~\cite{skyrim}. Interestingly enough, the hub structure mimics the literary hero's journey quite well. It has a distinct "home base" from where the hero ventures out into the unknown and dangerous lands to face obstacles, only to return to his home a changed person. This is a structure that has been well researched in many old texts, such as the myths and tales centered around King Arthur. Spearing describes this in his work on Sir Gawain and the Green Knight. A knight in search of honor leaves the round table and the comfort of Camelot to seek his fortune. He faces dangers and characters that change him and eventually returns home. He now understands this place of familiarity differently, not because \textit{it} has changed, but \textit{he} has.~\cite{Spearing1994}\\
It has been on purpose that I wrote of the game and the narrative as two distinct, even if interlinked, entities. I agree with Aarseth that what may resemble narrative structures is actually spatial (go from $A$ to $B$) structures. Games that might appear the most story-like, are in fact, often reliant on place-oriented quests and very spatially constrained. The challenge for game developers, as he puts it, is to "\textit{[...] move beyond the constraints of unicursal corridors or multicursal hub structures while keeping the player’s attention on a storyline. And that is no easy task. But perhaps presenting an interesting landscape with challenging quests is enough?}" This is exactly what the prototype of this thesis attempts to do.~\cite{Aarseth2005}
\section{Game Mechanics}
In the previous sections, I talked at length about the different requirements for a story in video games and how the narrative relates to the gameplay. In this part, I will discuss the topic of game mechanics in general. To talk about a story \textit{as} the game mechanic through the exchange of information, I need to provide sufficient definitions in both areas.\\
One robust definition was provided by Cook in 2006. He describes game mechanics as "\textit{rule based systems / simulations that facilitate and encourage a user to explore and learn the properties of their possibility space through the use of feedback mechanisms.}" At the center of this definition are feedback loops for learning new information. The definition is well illustrated as a diagram (Figure~\ref{fig:cookGameMechanics}).~\cite{Cook2006}
\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{cookGameMechanics.jpg}
	\caption{Cook's definition of game mechanics~\cite{Cook2006}}
	\label{fig:cookGameMechanics}
\end{figure}
For my project, I chose to follow Sicart, who describes another suitable formal definition of game mechanics. It stems from object-oriented programming while still keeping many ludological aspects such as the figure of players or agents as fundamental parts to understand how games are designed and played. He does so by purposely distinguishing between game mechanics and game rules. The former are the options of interactions available to an agent in the game. The latter are the restrictions under which those options are made available and how they change the game state. Sicart arrives at the definition of game mechanics as "\textit{methods invoked by agents, designed for interaction with the game state."} The first part of this definition is rooted in the paradigm of object-oriented programming. This appropriation of terminology is useful because it provides a formalistic perspective to actions performed in information systems like games. This can even lead to the application of modeling languages like UML (Unified Modeling Language) to the description of game systems.~\cite{Sicart2008}\\
In object-oriented programming, a method is the actions or behaviors available to a class. Methods are the functions an object has for calculating data or interacting with other systems or objects.~\cite{Weisfeld2008}\\
Following this logic, a game mechanic is an action invoked by an agent to interact with the game world, as constrained by the game rules. \textit{Super Mario 64}~\cite{mario64} usually allows the player to jump. If Mario is standing on quicksand, however, he will slowly sink into the ground, and jumping repeatedly will only bring him back to the surface. That means a mechanic is limited by the rules that apply to the game world, such as physics simulations. Mechanics can also be limited by rules that are applied to mechanics in specific game state contexts, like being only able to attack when a weapon is equipped.\\
The object-oriented approach of invoking methods for interactions decouples the inter-action from actual player input. On this systemic level, Sicart is able to talk just about agents that are interacting with the game world and not necessarily player interactions. Game mechanics can be invoked by any agent in the game, be that human or part of the computer system. Agents using artificial intelligence also have a number of methods available to interact with the game world. How actual player interactions are then mapped to input devices can be viewed separately.\\
The second part of the definition says that game mechanics are methods "\textit{designed for interaction with the game}". These interactions modify the game state. Game developers design basic mechanics that enable the player to overcome obstacles in the game. Challenges here describe gameplay situations in which the player has to invest an effort to progress further. All challenges are matched with a mechanic: by jumping, Mario can reach a higher-up area. By striking with an equipped weapon, a character can damage an enemy. The fact that games are structured as systems with mechanics, rules, and challenges is understood as the essential grammar of video games.~\cite{Sicart2008}\\
I have touched upon the fact earlier that there is more to the act of playing a game than just interacting with mechanics constrained by rules. In the act of playing, players will appropriate agency within the game world and behave in unpredictable ways. As mentioned before, it is one thing that a designer intends for the player to feel, and another, how players actually interact with the game world. The formal, analytical understanding of mechanics only allows us to design and predict courses of interaction but not to determine how the game will always be played or what the outcome of that experience will be. Designers can build rules and challenges with specific emotions in mind that they want to invoke in the player and then create matching mechanics that allow overcoming the challenges and thus create other resulting emotions.\\
This systemic approach makes two methods of analyzing game mechanics possible: For one, it allows to systemically analyze the structure of games in terms of actions available to agents to overcome challenges. The second perspective is the analysis of how actions are mapped onto input devices and how mechanics can be used to create specific emotional experiences in players. Sicart does, however, point towards gray areas in his definition. Perhaps the most significant is the categorical distinction between rules and mechanics. It is part of ongoing scientific discourse if mechanics are, in fact, a subset of rules. He argues, however, that rules are normative while mechanics are performative and that, therefore, this ontological distinction can be beneficial for the analysis of computer games. Game studies history shows that there is no dominant definition of key concepts like rules or mechanics. It is, in fact, the core message of Sicart’s work that it is possible and useful to understand game mechanics as different from game rules, and in that understanding, it can more clearly be described how games can be designed to affect players in new and innovative ways.~\cite{Sicart2008}
\subsection{Emergence Games}
The game mechanic that is developed as part of this thesis should allow players, as stated, to introduce, exchange, and retrieve pieces of information from a system of agents for the purpose of very individual narrative paths. This \textit{very individual} aspect of the mechanic invites the concept of emergence into the design process. Juul wrote about emergence games as opposed to games of progression.\\
Emergence happens when the whole is more than the sum of its parts when the activities of the parts do not simply add up to the activity of the whole~\cite{Holland2000}. Juul describes emergence games as those that have a small number of rules which combine to complex and varied results. It is in those games, where players tend to create strategies for dealing with the encountered results. Common examples for games of emergence are card and board games, most action games like fighting games, and all strategy games. Replayability is naturally high in emergence games, as are tournaments and existing strategy guides. Adventure games then introduced progression into video games. The player is confronted with a series of challenges that they have to overcome in a predefined way and order. Games of progression can be controlled by game designers much easier and more tightly. Historically this is also where most narrative games find themselves since the more linear and controlled sequence of events lends itself to traditional storytelling techniques. For that reason, progression games more likely have walkthroughs, guides specifying all the actions needed to complete the game.~\cite{Juul2002}\\
Further, both concepts are not mutually exclusive, as emergence games can feature progression structures and vice versa. Juul defines several types of emergence:
\begin{itemize}
	\item \textbf{Rule interaction}: simply two or more rules yielding a new result when satisfied at the same time. An example would be that trees catch fire when struck with a lit torch in \textit{The Legend of Zelda: Breath of the Wild}~\cite{zeldabotw}.
	\item \textbf{Combination}: This type of emergence stems from the different potential game sessions that are created through the combination of different rules — for example, the procedurally generated 2D levels in \textit{Spelunky}~\cite{spelunky}.
	\item \textbf{Emergent strategies}: These are what Juul calls the actually emergent properties since they are not immediately derivable from the basic game rules. There are countless examples for this type, such as all game strategies or the need for cooperation with other players.
\end{itemize} 
Emergence does, however, not exclude all kinds of direction from designers. Games of emergence lie somewhere in between complete open games where the player is free to do what they please and closed up games where everything that can happen is predetermined.~\cite{Juul2002}\\ 
This makes the concept of emergence so attractive for this thesis since it would allow some form of narrative structure to remain in a system where the simple rules enable the player to come up with new and interesting solutions.
\subsection{Multiplicative Game Design}
Staying on the broader topic of emergence, another related concept is useful for designing game mechanics. \textit{Multiplicative gameplay} was used by the developers of \textit{The Legend of Zelda: Breath of the Wild}~\cite{zeldabotw} to describe their design approach of what they called "\textit{rediscovering the essence and breaking conventions}". Early in the development process, the game designers realized that they wanted to make the player feel a new sense of adventure again and again while having freedom of where to go and what to do. They realized, however, that previous \textit{Zelda} games had the following conventions that would keep them from that:
\begin{itemize}
	\item a predetermined sequence of events
	\item non-traversable walls and barriers
	\item a predetermined experience
	\item widely available answers for puzzles online
\end{itemize}
Interestingly these points sound exactly like what Juul describes as games of progression while the developers of Breath of the Wild wanted to create an emergence game. They did so by carefully examining the elements that were progressive in nature, removing them, and replacing them with systems that have emergent properties. Insurmountable cliffs, for example, were made climbable, and a stamina system for climbing was introduced. This was expanded to the whole 3D world, which immediately made the entire landscape traversable, given enough stamina. They applied interlinking systems to all their game objects which creates an immense variety of what Juul calls combination type emergence~\cite{Juul2002}. By embedding these systems into a robust physics engine to allow for varied but expected behavior, the developers were able to create satisfactory gameplay feedback for players, as discussed in section~\ref{section:expfee}. Exactly this interlinking of gameplay systems is what the developers call multiplicative gameplay. In \textit{Breath of the Wild}, they could even leverage the variety of interaction options to design the small shrine puzzles in the game. Because of the emergent nature of the game, the shrines often don't have a single correct solution but many that allow the players to explore and play around with mechanics.~\cite{fujibayashi2017}
\section{Concretizing Information}
\label{section:info}
In order to create a game mechanic based on game world state information, this information needs to be modeled in a way that can be interpreted by game rules. Information itself is quite an abstract thing until saved in some form of permanent medium like writing it down. It seems ironic that a general definition of information becomes ambiguous quickly. Etymologically the word comes from the Latin verb \textit{\={i}nf\={o}rm\={a}re}, which translates to "\textit{to give form to the mind}". Information has not only different meanings in different contexts, but even when just talking about information as something that is "informative", it becomes difficult to pin down. It can be the process of being informed, the thing one is being informed about, or a concrete thing that informs and "is informative".~\cite{Buckland1991}\\
There has always been a philosophical aspect to discussing information. A data-based definition of information seems most intuitive despite the fact that the nature of data is not well understood philosophically either. Nevertheless, data is a less rich concept and makes it easier to grasp.\\
The General Definition of Information by Floridi states the following:
\vspace*{0.5cm}
\makebox[1.5cm]{GDI)} $\sigma$ is an instance of information, understood as semantic content, if and only if:\par
\makebox[5cm]{GDI.1)} $\sigma$ consists of $n$ data (d), for n $\geq$ 1;\par
\makebox[5cm]{GDI.2)} the data are well-formed (wfd);\par
\makebox[5cm]{GDI.3)} the data are meaningful (wfd $= \delta$);\par
\vspace*{0.5cm}
This tells us a number of things. Firstly, information is made from data (GDI.1). Secondly, that data needs to be "well-formed", meaning it needs to be structured or bundled in the correct syntax, i.e., the rules of correctness for the analyzing system (GDI.2 and the first branch in Figure~\ref{fig:floridiInformation}). And finally, GDI.3) tells us that the data needs to be meaningful according to the semantics of the system (the second branch of Figure~\ref{fig:floridiInformation}). Both syntax and semantic are not necessarily linguistic constraints, but whatever those rules are for the governing system (e.g., a programming language or movie script format). Following the GDI information cannot be "dataless" since even the lack of data or unavailability of data is data in itself.~\cite{Floridi2010}\\
\begin{figure}
	\centering
	\includegraphics[width=0.8\textwidth]{floridiInformation.jpg}
	\caption{A data-based classification of information~\cite{Floridi2009}}
	\label{fig:floridiInformation}
\end{figure}
In Figure~\ref{fig:floridiInformation}, we can see a clear distinction between the different qualities of information, including factual properties. The leave nodes in the diagram denote the following types of information:
\begin{itemize}
	\item \textbf{Environmental}: Observed data that can be natural (e.g., rings in a tree trunk to estimate age) or engineered (e.g., the temperature from a thermostat).
	\item \textbf{Instructional}: Semantic data that conveys the need for a specific action (e.g., order, instructions, stipulations, invitations).
	\item \textbf{Misinformation}: Factual, wrong data, and the source \textit{is not} aware of its nature.
	\item \textbf{Disinformation}: Factual, wrong data, and the source \textit{is} aware of its nature.
	\item \textbf{Knowledge}: Factual, true information.
\end{itemize}
It seems clear how fast an attempt to generally define and classify information becomes a matter of philosophy.~\cite{Floridi2009}\\
The focus on semantics differentiates this more philosophical concept of information greatly from information theory. The science concerned with quantification, storage, and communication of digital information sees information as something entirely technical. The definition relates to the resolution of uncertainty. It understands information as that which reduces uncertainty. Now probability mathematics allows quantifying uncertainty, and that means information can equally be quantified. For sufficiently communicating information, information theory introduces the \textit{bit} as the unit of information. A bit is in a sense "\textit{that which halves uncertainty}" since a bit can only have two states, $0$ or $1$.~\cite{Shannon1948}\\
The information value of a given symbol is the uncertainty that the symbol is transmitted. That means the rarer it is for a symbol to be transmitted, the more information value it has. The logarithmic function is used to express the information value $I$ of symbol $x$ in a bit.
\begin{equation}
	I(x) = -\log_2 p(x)
\end{equation}
Where $p(X)$ is the probability of the symbol $x$ being transmitted, then the average information value of a transmitter $X$ is called entropy.
\begin{equation}
	H = \sum_{x \in X} p(x)I(x) = -\sum_{x \in X} p(x)\log_2 p(x)
\end{equation}
All this, of course, relates in practice to the transmission of information but still establishes a sense of measuring "informativity".~\cite{Shannon1949} Evaluating information based on its rarity can, of course, be useful for a game mechanic based on exchanging information.
\subsection{Communication}
The prototype game created as part of this thesis aims to emulate human communication by giving agents the ability to exchange information. Exchanging information is, of course, nothing else than communication. In order to simulate this, I looked into human communication. As being with the capacity for social interaction, the development of speech and the formation of languages is unique in humans~\cite{Levinson2006}. Communication is another concept that has been often researched and differently defined by scholars~\cite{Littlejohn2010}. However, there exists some consensus that the first evolutionary usage of spoken language was the representation of one's thoughts. This was followed by the function of exchanging ideas~\cite{Ruben1985}. Of the many available ones, I will choose the definition given by Adler et al. that "\textit{communication is the process of creating meaning through symbolic interaction}"~\cite{Adler2016}. It is described as a symbolic, relational process. Symbolic, as communication uses agreed-upon symbols to codify meaning, relational as communication needs adaption and coordination of the participating parties, and it is a process as it is not over after an isolated utterance or conversation. Sometimes the processing of received communication changes the thinking of the receiver over hours, days, or years.~\cite{Adler2016}\\
But human communication is imprecise. As humans, we are to a degree at the will of our emotions, and this means they also dictate the way we communicate with others. There are many reasons that can make human communication ineffective:
\begin{itemize}
	\item \textbf{Words are imprecise}: the languages we use for communication consists, of course, of words, and sometimes the words fail to accurately describe complex subject matters universally.
	\item \textbf{Coded language}: Humans always communicate somewhere in-between, wanting to be known and wanting to stay hidden. We use "codes" both involuntarily or not to make our messages more indirect or ambivalent.
	\item \textbf{The emotional factor}: As mentioned, emotions highly influence the way we communicate and how we receive what is communicated to us.
	\item \textbf{Attention and distractions}: When distracted or focusing on something else, it only makes sense that we either are unable to communicate effectively or receive everything correctly.
	\item \textbf{Reception filters}: Society conditions us to filter out some information channels to protect us from being overwhelmed. Also, conditioning through teaching or experience will create certain filters when receiving information or even may filter how information is interpreted depending on who the sender is.
	\item \textbf{Transmission interference}: Simple physical conditions can also contribute to an error in communications. There could, for instance, be a loud background noise that drowns out a verbal utterance or a stain on a book page covering an important written word.
\end{itemize}
These problems are not only restricted to human verbal communication but can occur, in varying degrees, in all kinds of communication.~\cite{Munsaka2014}\\
In addition to these universal human conditions, society is not a homogeneous group. Cultural differences, the purpose of communication, or the number of conversation participants also greatly influence the process~\cite{Chapanis1975}. These factors of imprecision of human communication all contribute to a difference in the intended information from the sender and the information that is understood by the receiving party. I collect and describe this difference under the umbrella term "\textit{Information Mutation}".
\subsection{Information Mutation}
I established that the relational aspect of human communication introduces a number of problems that need to be addressed and accounted for in everyday life. But not only is it difficult to preserve the integrity of information while it is sent, transmitted, and received, retaining information as the receiver also comes with its own set of hindrances.\\
The part of the human brain responsible for storing information is, of course, the memory. In the following paragraphs, I will use the terms information and memory more or less interchangeably for better understanding. With memory, I mean the encoded information in the brain. We base our actions and decisions on experience that is stored in the memory in the form of memories~\cite{Sherwood2015}. The existence of memories is a necessity for the development of language, relationships, or even personal identity~\cite{Eysenck2012}.\\
Disremembering or forgetting is something everyone experiences. It is the apparent loss or modification of information that was already encoded and stored in the short or long-term memory. Even when it is not due to an illness or defect of the brain itself, humans forget things. Forgetting can be both spontaneous or a gradual process after which old memories are unable to be retrieved from the memory. Studies show that retention of information improves by increasing rehearsal. Rehearsal helps to transfer information to long-term memory.~\cite{Weiten2021}\\
It seems to be a natural part of the brain's function, but there exist multiple theories on why that is.
\subsubsection{Decay Theory}
The Decay theory proposes that memory fades as a function of the passage of time. What that means is that information is less available for retrieval as time passes and memory strength decreases. The new acquisition of information creates a neurochemical "memory-trace". As time passes, this trace slowly decays. Scientists suspect that active rehearsal or repetition helps counteract this effect~\cite{Oberauer2008}. Although it is assumed that neurons in the brain slowly die off with increasing age, there are older memories that can be stronger than younger ones. The Decay Theory applies, therefore, especially to short-term memory. That means older memories in the long-term memory are often more resilient against shock, trauma, or physical attacks on the brain. The passage of time is also probably not the sole reason for forgetting.~\cite{Berman2009}
\subsubsection{Interference Theory}
Interference occurs when learning new information. The Theory proposes that memories encoded in the long-term memory are being forgotten and cannot be retrieved into the short-term memory. This would be because a memory in one interferes with the memory in the other. There is an immense amount of encoded memory in long-term memory. The challenge of remembering is to retrieve a single specific memory from long-term memory and transfer it into short-term memory for processing. There are two types of interference effects, proactive and retroactive interference.~\cite{Edwards2010}\\
Proactive interference is the inhibition of the retrieval of new memories caused by old memories. Of the two effects, proactive interference is the rarer one and the less severe one. The hypothesis exists that without proactive interference, it would be impossible to forget information in the short-term memory.~\cite{Keppel1962}\\
Retroactive interference then is the inhibition of retrieval of long-term memories by newer memories. In more intuitive terms, that means that learning new information directly leads to forgetting older memories. The effect takes place when any previously learned information is not rehearsed for a longer period of time. Retroactive interference is the more frequent and more problematic of the two effects because it leads to the unlearning of information~\cite{Melton1941}.~\cite{Edwards2010}\newline

For the remainder of this paper, I chose the term "\textit{information mutation}" to collect all these processes under a single, more intuitive word. It stems from the Latin word \textit{mutatio} for change, or alteration and works well for the purpose of describing both decay and interference. 
\section{Multi-Agent Systems}
As previously stated, the resulting prototype game from this thesis should simulate an interactive environment with NPCs that exchange and process information about the world state. Multi-agent systems (MAS) provide a suitable concept to interpret NPCs as autonomous, interacting agents.\\
A MAS is a computational model for simulating actions and interactions of intelligent, autonomous agents~\cite{Wooldridge2009}. In the model, agents can represent both individuals and groups. The idea is that the resulting simulations can give a greater understanding of behavior systems or solve specific computational objectives. MASs are part of a growing research area and are applied in many different scientific fields such as ecology, economy, social sciences, biology, engineering sciences, physics, or, in fact, video games. Any field that is concerned with systems of many autonomous interacting entities can profit from MASs. Because of the ever more rapid advancements in computing power, these models can grow ever more complex, detailed and precise in structure and size, where previously, simpler models relying on less processing heavy assumptions were needed.~\cite{Helbing2012} The term multi-agent system is commonly used in areas such as engineering  and artificial intelligence, whereas other sciences also refer to agent-based modeling~\cite{Niazi2011}.\\
In MASs, agents live in an environment. It is the surrounding space (either in the Cartesian sense or conceptual) in that the agents exist and perform actions. Environments can have different characteristics that are worth mentioning. An \textit{accessible} versus an \textit{inaccessible} environment allows the agent to obtain complete, accurate, and up-to-date information about the environment state. \textit{Deterministic} and \textit{non-deterministic} environments are different in the fact that in the former, any action has a single guaranteed effect, and there is no uncertainty about the resulting state of the environment. \textit{Static} environments can be assumed to remain unchanged except by the acting agents' actions as opposed to \textit{dynamic} environments. Finally, \textit{discrete} versus \textit{continuous} environments differ in the fixed and finite number of actions and percepts in them.~\cite{Wooldridge2009}\\
The basic building blocks of MASs, the agents, can become complex models in themselves. They are worth a closer examination to better understand how NPCs can be modeled into agents.
\subsection{Agents}
Depending on the context the MAS is applied to, there exist manifold definitions for what exactly an agent is. For this thesis, I will adhere less to a concrete definition but to a set of properties that an agent must have to be considered as one:
\begin{itemize}
	\item \textbf{Autonomy}: A agent must be able to function independently in its environment. Its interactions are not necessarily dependent on other agents, and it uses its capabilities to sense its environment to form decisions and actions.
	\item \textbf{Self-containment}: The agent has a definitive set of operations, attributes, and characteristics that make it a discrete individual entity. It has a systemic "boundary" that makes it possible to determine what is or what is not part of an agent and what might be a shared characteristic between agents.
	\item \textbf{Interaction}: To leverage the capabilities of a MAS, agents need to interact with each other. They have protocols that commonly include recognition of other agents, collision avoidance, information exchange, influencing other agents. These interactions can be very specific to the domain the MAS is applied to.
\end{itemize}
Other properties for agents that could be considered as defining attributes can include \textit{environmentally dependent}, which would mean that the agent's state is dependent on its situation in the environment, \textit{having goals} that can describe objectives or measurements for the agent's effectiveness, \textit{learning and adaption capabilities} to change behavior based on experience or \textit{resource attributes} which track any metric of a resource an agent could earn, hold and spend.~\cite{Macal2009}\\
An example agent with its properties and indications of interacting with the environment and other agents can be seen in Figure~\ref{fig:macalAgent}.
\begin{figure}
	\centering
	\includegraphics[width=0.5\textwidth]{macalAgent.jpg}
	\caption{A typical agent~\cite{Macal2009}}
	\label{fig:macalAgent}
\end{figure}
\subsection{Intelligent Agents}
Agents with defined behaviors have a number of actions available to them that modify the environment around them. Not all actions can be necessarily performed at the same time. Usually, certain preconditions have to be satisfied, which might be highly depending on the current context or restrictions of the agent. Agents are equipped with \textit{sensors} that are able to perceive the environment and changes in the same. An internal decision-making logic will determine the action to perform, and the \textit{actuators} of the agent will then perform the action. This might then result in changes in the environment that other agents are again able to "sense" (Figure \ref{fig:wooldridgeAgent}). The main issue when designing agents is to create their ability to decide \textit{which} actions they should perform in a given context to best satisfy their design objective.~\cite{Wooldridge2009}\\
\begin{figure}
	\centering
	\includegraphics[width=0.7\textwidth]{wooldridgeAgent.jpg}
	\caption{An agent as a state machine~\cite{Wooldridge2009}}
	\label{fig:wooldridgeAgent}
\end{figure}
This decision-making logic usually comes with the implication of "\textit{intelligence}". For this thesis, I will follow Wooldridge and Jenning's list of "intelligent" characteristics of intelligent agents:
\begin{itemize}
	\item \textbf{Reactivity}: the ability to perceive the environment and respond to changes that occur to satisfy design objectives.
	\item \textbf{pro-activeness}: select actions to be taken in a goal-directed manner. This is different from reactivity in so far as to change the agent's behavior before the fact.
	\item \textbf{Social ability}: the capability to use interactions with other agents to satisfy design objectives.
\end{itemize}
The characteristic that makes an agent "intelligent" are quite demanding in their conception and implementation since they require logic that takes a changing environment into account. In scenarios with many agents that act in an environment at the same time, this becomes very complicated fast.~\cite{Wooldridge1995}
\subsection{State Machines}
A useful approach to help with the design of intelligent agents is viewing them as state machines or agents with a state. State machines work on the basis of nodes that represent a distinct state a system is in coupled with state transitions that occur if specific conditions are met~\cite{Hopcroft2001}. Each subsystem inside the agent can be seen as a state that the agent can take on. This helps a lot with the conceptual thinking of data transfer and the internal operations of the agent. It also allows for the employment of classical software engineering paradigms that are well tried and tested, and widely understood.~\cite{Wooldridge2009}\\
There exist multiple standards for defining and visualizing the structure of state machines. They tackle the challenges of designing large and complex reactive systems. Since being \textit{reactive} is one of the main characteristics of an intelligent agent, it makes sense to employ strategies that help with the design of such a system.~\cite{Harel1985}\\
A reactive system is characterized by being highly influenced by events outside and inside of the system. It is no trivial task to describe this kind of behavior in a way that is clear and realistic while retaining a sense of formality and rigorousness. Harel describes a visual formalism for designing and visualizing state machines that is based on box-shaped state nodes with arrows as state transitions (Figure \ref{fig:harelState}). From this basis, Harel's work goes on to describe more complex visualizations for larger and more varied state machines, including behaviors like concurrency, clustering, or conditional transitions.~\cite{Harel1987}\\
\begin{figure}
	\centering
	\includegraphics[width=0.5\textwidth]{harelState.jpg}
	\caption{A simple state diagram~\cite{Harel1987}}
	\label{fig:harelState}
\end{figure}
\subsection{Games as Multi-Agent Systems}
It is quickly apparent how multi-agent systems could be leveraged to create a game world as an environment filled with autonomous NPC characters as intelligent agents.\\
The way game engines are built, they usually decouple subsystems like rendering, sound, physics, or user input from each other. Those systems are not easy to standardize, though, because they are oftentimes hardware-dependent and might not even need optimization for most use cases. The game logic is the subsystem in which game programmers implement the rules on which game mechanics are based. It is here where the heart of a video game beats. It is visible now that we can see a video game as a system and certain objects that act in the game as agents. Now, these agents need to adhere to the game’s rules that are defined by the game designers. The game logic is thus implicitly related to the game objects internal processes that are associated with their autonomous agent’s actions. The available actions are again dependent on the game mechanic, which forms the preconditions for state transitions that make actions available to agents. There now exists a link between game mechanics designed by designers to state transitions that define the decision-making of intelligent agents. The autonomous behaviors are also dependent on the communications between the objects of the game, either sending information about the game state or about the game object’s state.~\cite{MarinLora2020}\\
This approach of realizing NPCs as intelligent agents in video games has not been explored often by developers yet. It is very likely that this would yield more compelling gameplay, as I have described in earlier sections. We only slowly see more games in which agents actually interact with each other autonomously. For games in which interaction is simple, this would not be problematic to add. More complex interactions, however, can yield to unexpected and unwanted behavior of agents, especially if multi-agent interactions were not designed as an essential part of the game. Interactions between agents with conflicting goals could lead to two characters fighting whose interests would actually be aligned in the game world when they could actually find common ground on their goals and resolve the issue without conflict. There exists work on sharing, exchanging, and rejecting goals in traditional artificial intelligence studies~\cite{Kraus1997}. The game developer community has yet to pick up this trend. This thesis aims to be a bridge between both fields.~\cite{Dignum2009}\\
Computing power again becomes an issue when talking about decision-making for in- intelligent agents in games. Complex calculations that take up a lot of processing power might be needed to generate agent behavior. Video games already have high demands on computing power. The display of high fidelity graphics, the simulation of realistic physics, 3D audio playback, and network communications are only some of the expensive operations for both the processor and the graphics card. Developers, therefore, often have to reduce the complexity of their game logic algorithms which includes the internal logic of agents. Especially with multiple agents in a game that all form decisions in parallel, this can become a problem very quickly. In later sections, I will go into more detail about what my approach was to find a possible countermeasure for this problem for the prototype game of this thesis. Persistence is yet another issue that multi-agent system-based games would need to address. Serializing a current game state at any moment is not a trivial task as is. Add multiple interacting agents that all have their own state to interrupt and resume when the game is continued, and the result is a very complex problem.~\cite{Dignum2009}\\
I have now described how NPCs can be defined as intelligent agents in a video game and the challenges this approach brings. For the more concrete scenario of the game mechanic that was implemented as part of this thesis, information exchange is at the basis of the prototype game. NPCs that share information about the game world and other agents need some form of a protocol of exchange. In the next section, I will describe how consensus protocols can be used to establish an understanding between agents.
\section{Consensus}
In complex computing systems, a real and fundamental problem is the problem of consensus. That means an overall ground truth that all participating agents reliably agree on even in the presence of faulty actors. There are numerous techniques and algorithms for coordination processes that result in agreeing on data values. Common real-world examples for consensus-dependent applications are committing database transactions, cloud computing, load balancing, blockchain, or clock synchronization. The basic consensus problem is the agreement of multiple agents on a single data value. During the operation of a system, some agents can fail or become unreliable due to errors. This means that consensus protocols need to be fault-tolerant.~\cite{Van2002}\\
A basic approach to consensus is agreement on a majority value. How a majority is defined can again be different depending on the protocol, but at least one more than half of the available votes are needed for a majority. Usually each agent gets one vote which also can lead to an incorrect consensus or none at all. A \textit{quorum} is a popular choice for finding a majority.
\subsection{Quorum}
From the Latin noun \textit{qu\=orum}, a quorum is the minimum number of votes an agent has to obtain in order to be allowed to perform an operation in the system. Quorum-based techniques ensure consistency in the system.  The idea works as follows. Every agent in the system gets a vote $v_{i}$. The total number of votes in the system is $V$, and the accept and reject quorum numbers are $V_{a}$ and $V_{r}$. The following rules must be satisfied in the implementation of the acceptance protocol:
\begin{enumerate}
	\item $V_{r} + V_{a} > V$, where $0 < V_{a}, V_{r} \leq  V$.
	\item Before a process accepts, it must obtain an accept quorum $V_{a}$. That means the total of at least one agent that is prepared to accept and zero or more agents waiting $\geq V_{a}$.
	\item Before a transaction rejects, it must obtain a reject quorum $V_{r}$. That means the total of zero or more agents that are prepared to reject or any agents waiting $\geq  V_{r}$.
\end{enumerate}
The first rule ensures that a vote cannot be accepted and rejected at the same time. The next two rules indicate the votes that an agent has to obtain before it can terminate one way or the other. Choices for quorum numbers are, of course, important decisions that influence the whole system.~\cite{Ozsu1999}
\subsection{Consensus Protocols}
Consensus protocols must follow some requirements in order to function properly if they are expected to tolerate a limited number of failures in the participating agents' processes.
\begin{itemize}
	\item \textbf{Termination}: eventually, every correct process decides some value
	\item \textbf{Integrity}: if all the correct processes proposed the same value $x$, then any correct process must decide $x$
	\item \textbf{Agreement}: every correct process must agree on the same value
\end{itemize}
System architecture varies greatly depending on the system domain. Consensus problems occur in all kinds of multi-agent systems independent of the attributes of the message exchange channels. Most communication models have authenticated channels meaning the participants are not anonymous. Senders and receivers of messages are known to the other respective participants. Some systems introduce a stronger, transferable form of authentication, where every participant "signs" the message so that the final receiver will know every processor from the original sender to itself. This form of authentication can tolerate a larger number of faults for the consensus protocol.~\cite{Coulouris2001}\\
In a consensus problem, there are only two types of failures for processes of participating agents:
\begin{itemize}
	\item \textbf{Crash failure}: a process simply stops abruptly and does not recover
	\item \textbf{Byzantine failure}: a process appears to be failing, but it is unclear if it has actually failed. This includes malicious actions and attacks, which makes Byzantine failures the more disruptive class of failures. It is named after "\textit{The Byzantine Generals Problem}"~\cite{Lamport1982}.
\end{itemize}
A consensus protocol tolerating Byzantine failures must be able to fend off every possible error that can occur.~\cite{Coulouris2001}\\
Synchronicity is another important aspect of consensus protocols. To approximate the asynchronous nature of real-world communication, systems are often modeled as synchronous. In synchronous systems, communication happens in rounds. A process sends all its messages in one round and then receives all messages from other processes. Therefore, no message is allowed to influence another message in the same round.~\cite{Coulouris2001}\\
Usually, there is a configuration process prior to any communication that permissions agents to take part in the communication. If no such authentication of agents takes place, the system is open to attacks that simply create enough virtual participants that vote in the attacker's favor, so-called "\textit{Sybil Attacks}". There are, however, permissionless protocols that allow anyone to join the protocol. For those systems, there is another cost or barrier involved. Bitcoin is, of course, famous for introducing the first permissionless consensus protocol that uses Proof of Work to earn the right to participate~\cite{Gervais2016}. There are other permissionless consensus protocols such as Proof of Stake, Proof of Space, Proof of Authority, or Proof of Personhood, which is a promising approach for consensus among NPCs.~\cite{Coulouris2001}
\subsection{Proof of Personhood}
Going forward, I will view the system of NPCs and how they exchange information as an asynchronous, permissionless consensus problem. Asynchronous because characters only exchange information when they encounter other characters or events in the world that create a piece of information and permissionless because, in a "social" group of NPCs and a player, there is no specified process for authentication before taking part in the information exchange. Proof of Personhood is a technique that has humans at its center to ensure authenticity.~\cite{Borge2017}\\
The idea is to guarantee each unique participant an equal amount of votes independent of economic investment. This differs greatly from other permissionless consensus proto- cols like Proof of Work or Proof of Stake, where voting power is given proportionally to an investment from the participant. Social and democratic tendencies are clearly apparent to have a part in this approach. Blockchain systems that are more or less established now, like Bitcoin and Etherum, cannot possibly claim social fairness since a comparably small number of big players can hold and thus control choices on the blockchain. [86] The previously mentioned Sybil attacks are a central problem for identity-based protocols. They create a large amount of fake virtual identities to gain a controlling majority in a system~\cite{Douceur2002}.\\
This "unique human" or "semi-unique human" problem has resulted in a lot of research towards network protocols that make use of subjective inputs. Voting, vouching, or interpreting are measures taken to create a Sybil-resistant consensus for identity to create fairer, more social digital networks for humans.~\cite{Siddarth2020}\\
In order to guarantee protection from Sybil attacks, every identity in the network needs to be \textit{unique} and \textit{singular} to ensure that no two people have the same identifier, and no person should be able to have more than one identifier. There are two other requirements for Proof of Personhood approaches: The first is \textit{self-sovereignty} which ensures that anybody can create and control an identity without any influence of a centralized third party. The second is being \textit{privacy-preserving} which means that every participant can acquire and use their identifier without revealing personal information in the process. Proof of Personhood protocols tackle these three requirements by utilizing the following concepts:
\begin{itemize}
	\item \textbf{Subjective substrate}: Proof of Personhood needs some form of "task" to replace the computational work of Proof of Work or the financial stake of Proof of Stake protocols. Such a substrate would need to be easy for humans to produce but difficult for artificial intelligence. Furthermore, it would need to be difficult to produce for humans \textit{twice} while involving zero or absolutely minimal personal information.
	\item \textbf{Objective incentive}: There needs to be an incentive to participate strong enough so that it is more valuable to be a part of the network as a legitimate agent than as a fake identity.
\end{itemize}
Some examples of Proof of Personhood applications include CAPTCHAs to prove that a user is a human or a very basic approach of so-called "pseudonym parties". They build on the fact that humans can only physically be at one place at a time.~\cite{Siddarth2020} In this method, humans physically meet at a specific location and time to confirm their authenticity at the meeting, for example, by scanning QR codes that create anonymous credentials~\cite{Borge2017}.\\
Part of the prototype game was finding a suitable subjective substrate for NPCs to base their information exchange on. I designed a heuristic for information believability that NPCs take into account when receiving a new piece of information.
\section{A Heuristic for Information}
The term "heuristic" comes from the Greek $\varepsilon\acute{\upsilon}\rho\acute{\iota}\sigma\kappa\omega$, which translates to "I find" or "I discover". Heuristics are techniques that approach exact results rather than exactly calculating them. Any method that reaches a sufficient approximation for a given problem in less time than traditional or correct methods can be described as a heuristic.~\cite{Ippoliti2015}\\
In computer science, heuristic functions also approximate an exact solution for otherwise potentially expensive calculations~\cite{Pearl1984}. For the prototype game of this thesis, I came up with a heuristic that allows NPCs to evaluate incoming information with regard to their believability. It is a calculation that should simulate the cognitive process of "thinking about" something that a character learns. Even though it is an approximation of such a process, it is quite an expensive calculation. 
\subsection{MapReduce}
\textit{MapReduce} is a programming model that allows the distribution of calculations on big data sets to reduce the workload for single processes. I applied the \textit{MapReduce} concept while designing the heuristic function so that results become available in a reasonable time. The distribution of large datasets using a large number of computers is collectively referred to as a cluster or a grid. While this process often appears inefficient compared to algorithms that are more sequential, \textit{MapReduce} can be applied to significantly larger datasets than a single server can handle. For example, a large server farm can use \textit{MapReduce} to sort a petabyte of data in only a few hours~\cite{Czajkowski2011}. \textit{MapReduce} frameworks consist traditionally of the following three operations:
\begin{enumerate}
	\item \textbf{Map}: each processing node applies a \textit{map function} to a local dataset, the result is written to temporary storage. In a MapReduce framework, a master node ensures only one copy is processed, and no redundancy occurs. Map functions, as the name implies, "map" the input data to an output key.
	\item \textbf{Shuffle/Sort}: Data is redistributed based on output keys. Results with the same output key are transferred to the same nodes for further processing.
	\item \textbf{Reduce}: The collected groups of data are now processed in parallel on the respective nodes. This is performed using aggregate operations that "reduce" the group to a single value.
\end{enumerate}
\textit{MapReduce} allows distributed processing of the map and reduction functions. The mapping can be performed in parallel if the operations are independent of each other. Similarly, the reduction phase can be processed in parallel as well. For this to function properly, all outputs of the map operation that share the same key need to be presented to the same reducer at the same time, or the reduction function needs to be associative. Figure \ref{fig:mapReduce} shows a schematic view of a MapReduce framework.~\cite{Dean2008}
\begin{figure}
	\centering
	\includegraphics[width=0.8\textwidth]{jacobsenMapReduce.jpg}
	\caption{A MapReduce framework with a map function $f1$ and reduce function $f2$~\cite{Dean2008}}
	\label{fig:mapReduce}
\end{figure}
\section{Inference Engines}
I have established that NPCs will "think about" and evaluate the information they receive. Additionally, they also have a routine that allows them to "reflect" on information they already possess. According to a specified set of rules, agents can "deduce" new information in the form of: "If I have information $A$ and information $B$ and the rule $A \wedge B \Rightarrow C$ exists, then I will learn information $C$." Logic inferences like this can be produced with so-called \textit{inference engines}.~\cite{Hayes1983}\\
For an inference engine to work, a knowledge base needs to be present. The collective information set of an agent can represent such a knowledge base. The inference engine applies logical rules to the knowledge base and deduces new knowledge. This process is executed repeatedly until no new knowledge is deduced since each new fact could trigger new rules to apply. There are two modes, rules that can be applied in an inference engine: \textit{forward chaining} and \textit{backward chaining}. Forward chaining takes the known facts in the knowledge base and creates new facts based on the inference rules. Backward chaining starts by looking at the goals and then determines the facts that need to be asserted for the goals to be true. An example would be the following inference rule in pseudo-code:
\begin{equation}
	\textit{isAgentArmed}(a) \wedge \textit{isAgentEnemey}(a) \Rightarrow \textit{isAgentDangerous}(a)
\end{equation}
The rule states that if an agent $a$ is both \textit{armed} and an \textit{enemy}, then the agent should also be considered \textit{dangerous}. Forward chaining would look at each fact in the knowledge base and search for facts for an agent $a$ that state that said agent is \textit{armed} and an \textit{enemy}. The rule would then add the fact that agent $a$ is also \textit{dangerous}.\\
Backward-chaining would look at the result \textit{dangerous} and then look for the prerequisites \textit{armed} and \textit{enemy} to then determine if agent $a$ is in fact \textit{dangerous}. Although implementation might sound similar, the conceptual approach to the two modes is different.~\cite{Feigenbaum1981}
\section{Related Work}
Even though the proposed game mechanic is novel in that it leverages multi-agent systems, there has been some work in similar fields, some of which I want to mention at this point.
\subsection{Emotion Engines}
\label{section:emotion}
In his Master thesis, Mizra explores emotion engines and how they can be applied to strengthen the narrative of video games. Emotion engines, in general, are computational models for approximating human emotions. Mizra provides a standardized way of adding emotional components based on any emotion theory and software engineering principles. This helps in designing an architectural paradigm for an emotion-oriented approach to game development. The framework also provides a way to generate an adaptive narrative not only for the story of the game but also other visual elements of the game. He defines the emotional states of agents as statecharts and personality as a mapping function. In the framework, events in the game world come with an emotion package that alters the emotional state of involved agents. This is a lightweight and very platform-agnostic approach that would be very valuable to add to the prototype of this thesis.~\cite{Mizra2021}
\subsection{Multi-Agent Systems and Sandbox Games}
Ocio and Brugos, in their paper on multi-agent systems and sandbox games, propose to start new research aimed at achieving more realistic sandbox games, building cities full of life, using, improving, or creating specific algorithms or techniques built upon existing work relating to multi-agent systems. They argue that sandbox games are suitable to be viewed as environments for intelligent agents. They furthermore provide an ar- architecture for agent-environment interactions as well as agent-agent interactions and an interface on how messages between entities could be structured. There has been a lot of research done into developing intelligent agents, but not much of that research has been taken over into video game development.~\cite{Barriales2009}